{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cda606-11bc-4363-a9fe-dad0c4dc1ef2",
   "metadata": {},
   "source": [
    "# Trip Advisor Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c112ba-940b-4a3f-8ded-74b30210e7dd",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "- Selenium\n",
    "- BeautifulSoup\n",
    "- Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1eeef-98ba-4fd3-ae57-626860404e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec292f1-2d11-4a7b-9816-d2cfd887f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firefox and Chrome\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43730a1d-c456-4fb3-b918-0274923dd97a",
   "metadata": {},
   "source": [
    "## Startup the webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e8dc5-d768-4e7c-b7f6-4a02e2a5fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eee011-f607-4f08-ac49-7eda4e3122b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.tripadvisor.com/Attraction_Review-g608497-d1515658-Reviews-Tegalalang_Rice_Terrace-Tegalalang_Gianyar_Regency_Bali.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81715da3-8edf-4a34-9f9c-461ae92bcb07",
   "metadata": {},
   "source": [
    "## Extract the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271c07d-4eeb-44bc-8389-cb3054faf8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fff91-2aac-4fbd-a958-f557e98afe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = soup.find('div', {'class': 'bPhtn'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fbd03-d7d4-4fa1-a2bb-dc849945663f",
   "metadata": {},
   "source": [
    "## Prototype the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f7828-2f15-41db-ae23-50e3f17703af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = parent.find_all('span', {'data-ft': 'true'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6efab3-7a6c-46ed-b7d5-bb800b740697",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c90195-e8b9-472e-b2e8-9246df79e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = results[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf5a74-6f2a-48cd-81c2-d1dd23f5914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = item.find('span', {'class': 'WlYyy cPsXC dTqpp'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c4a05-f22d-4398-a662-2e12c5025801",
   "metadata": {},
   "outputs": [],
   "source": [
    "cityParent = item.find('div', {'class': 'WlYyy diXIH bQCoY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719571d4-7aeb-4c9d-91f0-4f29e91164bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = cityParent.find('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b527a1-bf18-4f3e-8482-ce66b2ad8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = item.find('div', {'class': 'fEDvV'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33546c-7b38-4798-a44a-4dde192d5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = history[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a51d2-8846-4bf1-8971-4b37f14d0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = item.find('div', {'class': 'WlYyy diXIH dDKKM'}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9a56c-41cd-4681-bc9a-557c11b2e195",
   "metadata": {},
   "source": [
    "## Generalise the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec00290-02ac-4e89-9bda-8286e8737815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # name\n",
    "    try:\n",
    "        name = item.find('span', {'class': 'WlYyy cPsXC dTqpp'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    # city\n",
    "    try:\n",
    "        cityParent = item.find('div', {'class': 'WlYyy diXIH bQCoY'})\n",
    "        city = cityParent.find('span').text\n",
    "    except AttributeError:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    if 'contribution' in city:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    # date\n",
    "    try:\n",
    "        history = item.find('div', {'class': 'fEDvV'}).text\n",
    "        date = history[:8]\n",
    "    except AttributeError:\n",
    "        date = 'NaN'\n",
    "    \n",
    "    # review\n",
    "    try:\n",
    "        review = item.find('div', {'class': 'WlYyy diXIH dDKKM'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    return (name, review, city, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc6b1d-d4b3-4cd0-b3c5-33d871bdaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "parent = soup.find('div', {'class': 'bPhtn'})\n",
    "results = parent.find_all('span', {'data-ft': 'true'})\n",
    "del results[0::2]\n",
    "\n",
    "for item in results:\n",
    "    record = extract_record(item)\n",
    "    if record:\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe02f02-2e18-4d52-8efc-6caf6940c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in records:\n",
    "    print(row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632af7c0-6f18-4a50-8a43-a07602842776",
   "metadata": {},
   "source": [
    "## Getting the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7846a9-ad27-409a-ba00-31b95cc41d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(page):\n",
    "    \"\"\"Generate a url from page given\"\"\"\n",
    "    url = 'https://www.tripadvisor.com/Attraction_Review-g608497-d1515658-Reviews-or{}-Tegalalang_Rice_Terrace-Tegalalang_Gianyar_Regency_Bali.html'\n",
    "    return url.format(page * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691c224-240f-4c6e-ab5d-9c8faa45e732",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e8f20-bd6a-4eb9-8f97-d1a5d9bc2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Firefox and Chrome\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "def get_url(page):\n",
    "    \"\"\"Generate a url from search term\"\"\"\n",
    "    url = 'https://www.tripadvisor.com/Attraction_Review-g608497-d1515658-Reviews-or{}-Tegalalang_Rice_Terrace-Tegalalang_Gianyar_Regency_Bali.html'\n",
    "    return url.format(page * 10)\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # name\n",
    "    try:\n",
    "        name = item.find('span', {'class': 'WlYyy cPsXC dTqpp'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    # city\n",
    "    try:\n",
    "        cityParent = item.find('div', {'class': 'WlYyy diXIH bQCoY'})\n",
    "        city = cityParent.find('span').text\n",
    "    except AttributeError:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    if 'contribution' in city:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    # date\n",
    "    try:\n",
    "        history = item.find('div', {'class': 'fEDvV'}).text\n",
    "        date = history[:8]\n",
    "    except AttributeError:\n",
    "        date = 'NaN'\n",
    "    \n",
    "    # review\n",
    "    try:\n",
    "        review = item.find('div', {'class': 'WlYyy diXIH dDKKM'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    return (name, review, city, date)\n",
    "\n",
    "def main(pages):\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    \n",
    "    # start the webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for page in range(pages):\n",
    "        url = get_url(page)\n",
    "        driver.get(url)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        parent = soup.find('div', {'class': 'bPhtn'})\n",
    "        results = parent.find_all('span', {'data-ft': 'true'})\n",
    "        del results[0::2]\n",
    "\n",
    "        for item in results:\n",
    "            record = extract_record(item)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    # save data to csv file\n",
    "    with open('tripadvisor.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Name', 'Review', 'Origin', 'Date'])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd4842-89a4-4769-865d-a206c6786b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724eec6",
   "metadata": {},
   "source": [
    "## Page navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.tripadvisor.com/Attraction_Review-g608497-d1515658-Reviews-Tegalalang_Rice_Terrace-Tegalalang_Gianyar_Regency_Bali.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = driver.find_element_by_xpath('//span[@class = \"WlYyy CETAK\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40becdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = driver.find_elements_by_xpath('//button[@class=\"bHgte z Pc PQ Pp PD W _S Gn Z B2 BF Cj _M cbSHg eVjae fksET bxeeW ddFHE\"][@type=\"button\"][@aria-label=\"Select Filter\"]/div[@class=\"vsqao k u\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd131534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 5):\n",
    "    try:\n",
    "        ratings[i].click()\n",
    "\n",
    "    except WebDriverException:\n",
    "        print('element is not clickable', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    apply = driver.find_element_by_xpath('//button[@class=\"fGwNR _G B- z _S c Wc ddFHE ezIjy brHeh\"][@type=\"button\"]/span[@class=\"WlYyy bcUBw\"]')\n",
    "    apply.click()\n",
    "\n",
    "except WebDriverException:\n",
    "    print('wrong apply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "#     nextPage = driver.find_element_by_xpath('//div[@class=\"eRhUG\"]/a[@class=\"dfuux f u j _T z _F _S ddFHE bVTsJ emPJr\"][@aria-label=\"Next page\"]')\n",
    "    nextPage = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//a[@aria-label=\"Next page\"]'))\n",
    "    )\n",
    "#     nextPage.click()\n",
    "    \n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", nextPage)\n",
    "    driver.execute_script(\"arguments[0].click();\", nextPage)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "    print('cant go to next page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23238c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_xpath('//div[@class=\"cCnaz\"]')\n",
    "driver.execute_script(\"arguments[0].click();\", button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3afc9b",
   "metadata": {},
   "source": [
    "## Adding filter\n",
    "Adding filter to rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Firefox and Chrome\n",
    "from selenium import webdriver\n",
    "\n",
    "# webdriver exception\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "def get_url(page):\n",
    "    \"\"\"Generate a url from search term\"\"\"\n",
    "    url = 'https://www.tripadvisor.com/Attraction_Review-g608497-d1515658-Reviews-or{}-Tegalalang_Rice_Terrace-Tegalalang_Gianyar_Regency_Bali.html'\n",
    "    return url.format(page * 10)\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # name\n",
    "    try:\n",
    "        name = item.find('span', {'class': 'WlYyy cPsXC dTqpp'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    # city\n",
    "    try:\n",
    "        cityParent = item.find('div', {'class': 'WlYyy diXIH bQCoY'})\n",
    "        city = cityParent.find('span').text\n",
    "    except AttributeError:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    if 'contribution' in city:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    # date\n",
    "    try:\n",
    "        history = item.find('div', {'class': 'fEDvV'}).text\n",
    "        date = history[:8]\n",
    "    except AttributeError:\n",
    "        date = 'NaN'\n",
    "    \n",
    "    # review\n",
    "    try:\n",
    "        review = item.find('div', {'class': 'WlYyy diXIH dDKKM'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    return (name, review, city, date)\n",
    "\n",
    "def main(pages):\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    \n",
    "    # start the webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for page in range(pages):\n",
    "        url = get_url(page)\n",
    "        driver.get(url)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        parent = soup.find('div', {'class': 'bPhtn'})\n",
    "        results = parent.find_all('span', {'data-ft': 'true'})\n",
    "        del results[0::2]\n",
    "                \n",
    "        for item in results:\n",
    "            record = extract_record(item)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    # save data to csv file\n",
    "    with open('tripadvisor1.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Name', 'Review', 'Origin', 'Date'])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b958c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6fed34",
   "metadata": {},
   "source": [
    "## Final scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925001aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Firefox and Chrome\n",
    "from selenium import webdriver\n",
    "\n",
    "# webdriver exception\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # name\n",
    "    try:\n",
    "        name = item.find('span', {'class': 'WlYyy cPsXC dTqpp'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    # city\n",
    "    try:\n",
    "        cityParent = item.find('div', {'class': 'WlYyy diXIH bQCoY'})\n",
    "        city = cityParent.find('span').text\n",
    "    except AttributeError:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    if 'contribution' in city:\n",
    "        city = 'NaN'\n",
    "    \n",
    "    # date\n",
    "    try:\n",
    "        history = item.find('div', {'class': 'fEDvV'}).text\n",
    "        date = history[:8]\n",
    "    except AttributeError:\n",
    "        date = 'NaN'\n",
    "    \n",
    "    # review\n",
    "    try:\n",
    "        review = item.find('div', {'class': 'WlYyy diXIH dDKKM'}).text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    return (name, review, city, date)\n",
    "\n",
    "def main(pages):\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    \n",
    "    # start the webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    records = []\n",
    "    url = 'https://www.tripadvisor.com/Attraction_Review-g608497-d1515658-Reviews-Tegalalang_Rice_Terrace-Tegalalang_Gianyar_Regency_Bali.html'\n",
    "    driver.get(url)\n",
    "    \n",
    "    for page in range(pages):\n",
    "        if page == 0:\n",
    "            try:\n",
    "                filters = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '//span[@class = \"WlYyy CETAK\"]'))\n",
    "                )\n",
    "                filters.click()\n",
    "            except WebDriverException:\n",
    "                print('Couldn\\'t filter reviews')\n",
    "                driver.quit()\n",
    "                \n",
    "            try:\n",
    "                ratings = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, '//button[@class=\"bHgte z Pc PQ Pp PD W _S Gn Z B2 BF Cj _M cbSHg eVjae fksET bxeeW ddFHE\"][@type=\"button\"][@aria-label=\"Select Filter\"]/div[@class=\"vsqao k u\"]'))\n",
    "                )\n",
    "                \n",
    "                for i in range(3, 5):\n",
    "                    try:\n",
    "                        ratings[i].click()\n",
    "                    except WebDriverException:\n",
    "                        print('rating could\\'nt be selected', i)\n",
    "                        driver.quit()\n",
    "            except WebDriverException:\n",
    "                print('Couldn\\'t select all reviews')\n",
    "                driver.quit()\n",
    "            \n",
    "            try:\n",
    "                apply = driver.find_element_by_xpath('//button[@class=\"fGwNR _G B- z _S c Wc ddFHE ezIjy brHeh\"][@type=\"button\"]/span[@class=\"WlYyy bcUBw\"]')\n",
    "                apply.click()\n",
    "            except WebDriverException:\n",
    "                print('could not apply')\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        parent = soup.find('div', {'class': 'bPhtn'})\n",
    "        results = parent.find_all('span', {'data-ft': 'true'})\n",
    "        del results[0::2]\n",
    "        \n",
    "        for item in results:\n",
    "            record = extract_record(item)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "        \n",
    "        if page < pages - 1:\n",
    "            try:\n",
    "                nextPage = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '//a[@aria-label=\"Next page\"]'))\n",
    "                )\n",
    "\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", nextPage)\n",
    "                driver.execute_script(\"arguments[0].click();\", nextPage)\n",
    "            except Exception as e:\n",
    "                print('Couldn\\'t go to the next page')\n",
    "                print(str(e))\n",
    "        \n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    # save data to csv file\n",
    "    with open('tripadvisor.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Name', 'Review', 'Origin', 'Date'])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
